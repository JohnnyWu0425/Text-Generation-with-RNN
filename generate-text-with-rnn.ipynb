{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Import Package"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf \nimport tensorflow.keras as keras\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load & Explore Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_path = \"../input/nyt-comments/CommentsApril2017.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(dataset_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to prevent run out of memory, I only select part of dataset\ndataset = dataset[:1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = dataset[\"commentBody\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare Dataset for Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert all words to lowercase\nfor idx, sentence in enumerate(sentences):\n    sentences[idx] = sentence.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit all sentences on tokenizer\ntokenizer = keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# word index of tokenizer\ntokenizer.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of total words\ntotal_word = len(tokenizer.word_index)+1\nprint(\"Total number of word: \", total_word)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert sentences to sequences\nsequences = tokenizer.texts_to_sequences(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare training sequences\ntraining_sequences = []\n\nfor seq in sequences:\n    for i in range(2, len(seq)):\n        training_sequences.append(seq[:i])\n        \ntraining_sequences = np.array(training_sequences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Length of training_sequences: \", len(training_sequences))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# take a look on training_sequences\nprint(\"The first sequence in training sequences: \", training_sequences[0])\nprint(\"The second sequence in training sequences: \", training_sequences[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pad all sequences to make them same length\nlongest_len = max([len(l) for l in training_sequences])\ntraining_sequences = keras.preprocessing.sequence.pad_sequences(sequences=training_sequences,\n                                           maxlen=longest_len,\n                                           padding=\"pre\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare x_train and y_train\nx_train = training_sequences[:, :-1]\ny_train = training_sequences[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = keras.utils.to_categorical(y=y_train, num_classes=total_word)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of training_sequences: \", training_sequences.shape)\nprint(\"Shape of x_train: \", x_train.shape)\nprint(\"Shape of y_train: \", y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# model architechture\nmodel = keras.models.Sequential()\nmodel.add(keras.layers.Embedding(input_dim=total_word,\n                                 output_dim=64,\n                                 input_length=longest_len))\nmodel.add(keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)))\nmodel.add(keras.layers.Bidirectional(keras.layers.LSTM(128)))\nmodel.add(keras.layers.Dense(units=64, activation=\"relu\"))\nmodel.add(keras.layers.Dense(units=total_word, activation=\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load model weight: model was trained to get the accuracy of 0.95\ntry:\n    model.load_weights(\"../input/model-weight-generate-text-with-rnn/best_model_weight.h5\")\nexcept:\n    print(\"ERROR\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile model\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define custom callback for training\nclass CustomCallback(keras.callbacks.Callback):\n    \n    def on_epoch_end(self, epoch, logs):\n        if(logs[\"acc\"] >= 0.95):\n            self.model.stop_training = True\n\ncustome_callback = CustomCallback()\ncheckpoint = keras.callbacks.ModelCheckpoint(filepath=\"best_model.h5\",\n                                             monitor=\"acc\",\n                                             verbose=1,\n                                             save_best_only=True,\n                                             save_weights_only=True,\n                                             mode=\"auto\",\n                                             save_freq=\"epoch\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\nhistory = model.fit(x=x_train,\n                    y=y_train,\n                    batch_size=32,\n                    epochs=500,\n                    callbacks=[custome_callback, checkpoint])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Text with Trained Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"first_word = \"You\"\n\ngenerated_sentence = [first_word]\nnum_word_to_generate = 25","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generated_sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.texts_to_sequences(generated_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a dict to map idx to word\nidx2word = {idx:word for word, idx in tokenizer.word_index.items()}\nidx2word","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(num_word_to_generate):\n    \n    x = tokenizer.texts_to_sequences(generated_sentence)\n    \n    if len(x[0]) > longest_len:\n        x[0] = x[0][-1 * longest_len:]\n    else:\n        x = keras.preprocessing.sequence.pad_sequences(sequences=x,\n                                                   maxlen=longest_len,\n                                                   padding=\"pre\")\n    x = np.array(x)\n    y = model.predict(x)[0]\n    idx = np.argmax(y)\n    \n    generated_word = idx2word[idx]\n    \n    generated_sentence[0] += \" \" + generated_word","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generated_sentence","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}